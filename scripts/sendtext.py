import pyspark
import json
from pyspark.sql import SparkSession
from kafka import KafkaProducer
from kafka.errors import KafkaError
#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk-pom:1.11.538,org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell'
spark = SparkSession.builder.appName('testspark').getOrCreate() 

producer = KafkaProducer(bootstrap_servers=["b-1.demo-cluster-1.9q7lp7.c1.kafka.eu-west-1.amazonaws.com:9092",
"b-2.demo-cluster-1.9q7lp7.c1.kafka.eu-west-1.amazonaws.com:9092"],api_version = (0,10,1))

df = spark.read.csv("s3a://fumbabucket/Clean_Amharic.csv")

print(df.head())

for row in df.head(5):
    #print(json.dumps(row).encode('utf-8'))
    future = producer.send('group6_test',json.dumps(row).encode('utf-8'))
    try:
        record_metadata = future.get(timeout=10)
    except KafkaError:
        log.exception()
        pass
    print (record_metadata.topic)

